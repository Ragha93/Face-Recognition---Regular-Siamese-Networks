{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4121191a",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cdc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import HORIZONTAL,filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "from skimage import io\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61aefc",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8551dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "The current status is Trained\n"
     ]
    }
   ],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition Using SIAMESE NETWORKS\")\n",
    "canvas = tk.Canvas(window, width=1200, height=550,borderwidth=2).grid(columnspan=3, rowspan=30)\n",
    "\n",
    "entry1 = tk.Button(window,width=30,height=1,text ='Capture Training Image', command = lambda:show_frames(),fg='black',bg='#fa9801',font='Helvetica 8 bold')\n",
    "entry1.grid(column=0, row=0)\n",
    "\n",
    "entry2 = tk.Button(window,width=30,height=1,text ='Save Training Image', command = lambda:open_file(),fg='black',bg='#fa9801',font='Helvetica 8 bold')\n",
    "entry2.grid(column=0, row=1)\n",
    "\n",
    "entry3 = tk.Button(window,width=30,height=1,text ='Capture to unlock', command = lambda:Test_img(),fg='black',bg='#fa9801',font='Helvetica 8 bold')\n",
    "entry3.grid(column=0, row=2)\n",
    "\n",
    "entry4 = tk.Button(window,width=30,height=1,text ='Select Training image', command = lambda:open_train(),fg='black',bg='#fa9801',font='Helvetica 8 bold')\n",
    "entry4.grid(column=1, row=0)\n",
    "\n",
    "entry5 = tk.Button(window,width=30,height=1,text ='Train Model', command = lambda:Train_model(),fg='black',bg='#fa9801',font='Helvetica 8 bold')\n",
    "entry5.grid(column=1, row=1)\n",
    "\n",
    "entry6 = tk.Button(window,width=30,height=1,text ='Select Test image', command = lambda:open_test(),fg='black',bg='#fa9801',font='Helvetica 8 bold')\n",
    "entry6.grid(column=1, row=2)\n",
    "\n",
    "label5 =Label(window,text=\"The distance2 is: \")\n",
    "label5.grid(row=4, column=0)\n",
    "\n",
    "label6 =Label(window,text = \".\")\n",
    "label6.grid(row=4, column=1)\n",
    "\n",
    "label = Label(window)\n",
    "label.grid(row=10, column=0)\n",
    "\n",
    "label1 =Label(window)\n",
    "label1.grid(row=10, column=1)\n",
    "\n",
    "label7=Label(window,text=\"Phone Locked!!!!\",bg='#f03e3e',font='Helvetica 20 bold')\n",
    "label7.grid(row=50, column=1)   \n",
    "\n",
    "SNM = load_model(\"C:\\\\Users\\\\raghavendra.s.k\\\\Desktop\\\\Files\\\\LV\\\\Siamese_model_VGG.h5\")\n",
    "Status = 'None'\n",
    "\n",
    "#Capture Training image\n",
    "def show_frames():\n",
    "    global cv2image\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    result = True\n",
    "    while(result):\n",
    "        cv2image= cv2.cvtColor(cap.read()[1],cv2.COLOR_BGR2RGB)\n",
    "        result = False\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image = img)\n",
    "    label.imgtk = imgtk\n",
    "    label.configure(image=imgtk)\n",
    "    entry1.configure(text=\"Training Image Captured\",bg='#1fde72',font='Helvetica 8 bold')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#Model Training embedding\n",
    "def open_file():\n",
    "    global training_embedding,Status\n",
    "    if Status == \"None\":\n",
    "        training_embedding = embeddings(cv2image)\n",
    "        Status = \"Trained\"\n",
    "        entry2.configure(text=\"Model Trained\",bg='#1fde72',font='Helvetica 8 bold')\n",
    "    else:\n",
    "        print(\"Model already trained, press reset\")\n",
    "    print(f\"The current status is {Status}\")       \n",
    "    \n",
    "#Capture Test Image    \n",
    "def Test_img():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    result = True\n",
    "    while(result):\n",
    "        cv2image1= cv2.cvtColor(cap.read()[1],cv2.COLOR_BGR2RGB)\n",
    "        result = False\n",
    "    img = Image.fromarray(cv2image1)\n",
    "    imgtk = ImageTk.PhotoImage(image = img)\n",
    "    label1.imgtk = imgtk\n",
    "    label1.configure(image=imgtk)\n",
    "    Test_embed = embeddings(cv2image1)\n",
    "    distance1 = euclidean_distance(training_embedding,Test_embed)\n",
    "    label6.configure(text = distance1[0])      \n",
    "    if distance1[0]<0.25:\n",
    "        label7.configure(text='Phone Unlocked!!!',bg='#1fde72',font='Helvetica 20 bold')\n",
    "    else:\n",
    "        label7.configure(text='Phone Locked!!!',bg='#f03e3e',font='Helvetica 20 bold')\n",
    "    \n",
    "#Load train image file    \n",
    "def open_train():\n",
    "    global source_path\n",
    "    source_path = filedialog.askopenfilename()\n",
    "    if source_path :\n",
    "        \n",
    "#         cv2image2 = np.array(Image.open(source_path))\n",
    "#         img = Image.fromarray(cv2image2)\n",
    "#         imgtk = ImageTk.PhotoImage(image = img,size=(100,100))\n",
    "#         label.imgtk = imgtk\n",
    "#         label.configure(image=imgtk)\n",
    "        \n",
    "        entry4.configure(text = \"Training file selected\",bg='#1fde72',fg='black',font='Helvetica 8 bold')\n",
    "        print(source_path)\n",
    "    else:\n",
    "        pass    \n",
    "\n",
    "def Train_model():\n",
    "    global training_embedding1\n",
    "    if source_path :\n",
    "        cv2image = resize(np.array(Image.open(source_path)),(224,224,3))\n",
    "        print(cv2image.shape)\n",
    "        training_embedding1 = embeddings(cv2image)\n",
    "        Status = \"Trained\"\n",
    "        entry2.configure(text=\"Model Trained\",bg='#1fde72',font='Helvetica 8 bold') \n",
    "    else:\n",
    "        entry4.configure(text = \"Select File\",bg='#f03e3e',fg='black',font='Helvetica 8 bold')\n",
    "        \n",
    "def open_test():\n",
    "    global test_path,Test_embed1\n",
    "    test_path = filedialog.askopenfilename()\n",
    "    if test_path :\n",
    "        \n",
    "#         cv2image2 = np.array(Image.open(test_path))\n",
    "#         img = Image.fromarray(cv2image2)\n",
    "#         imgtk = ImageTk.PhotoImage(image = img,size=(100,100))\n",
    "#         label1.imgtk = imgtk\n",
    "#         label1.configure(image=imgtk)\n",
    "       \n",
    "        entry6.configure(text = \"Test file selected\",bg='#1fde72',fg='black',font='Helvetica 8 bold')    \n",
    "        cv2image2 = resize(np.array(Image.open(test_path)),(224,224,3))\n",
    "        Test_embed1 = embeddings(cv2image2)         \n",
    "        distance1 = euclidean_distance(training_embedding1,Test_embed1)\n",
    "        label6.configure(text = distance1[0]*100)\n",
    "        if distance1[0]<0.002050:\n",
    "            label7.configure(text='Phone Unlocked!!!',bg='#1fde72',font='Helvetica 20 bold')\n",
    "        else:\n",
    "            label7.configure(text='Phone Locked!!!',bg='#f03e3e',font='Helvetica 20 bold')\n",
    "    else:\n",
    "        pass           \n",
    "        \n",
    "\n",
    "def Image_resize(x):\n",
    "    img = (x / 255.).astype(np.float32)\n",
    "    img = cv2.resize(img, dsize = (224, 224))\n",
    "    return img    \n",
    "\n",
    "def embeddings(x):\n",
    "    img = Image_resize(x)\n",
    "    embedding_vector1 = SNM.predict(np.expand_dims(img, axis = 0))[0]\n",
    "    return embedding_vector1\n",
    "\n",
    "def euclidean_distance(x,y):\n",
    "    a= K.sqrt(K.sum(K.square(x - y), axis=-1, keepdims=True))\n",
    "    return a.numpy()\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b84ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287b3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "    '''Compute Euclidean Distance between two vectors'''\n",
    "#     x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def Image_resize(x):\n",
    "    img = io.imread(x)\n",
    "    img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    img = cv2.resize(img, dsize = (224, 224))\n",
    "    return img  \n",
    "\n",
    "# def L2_distance(emb1, emb2):\n",
    "#     return np.sum(np.square(emb1 - emb2))      \n",
    "\n",
    "# def L2_distance2(emb1, emb2):\n",
    "#     return np.sum(np.square(emb1)-np.square(emb2))\n",
    "\n",
    "\n",
    "# def L2_distance1(emb1, emb2):\n",
    "#     return 1-spatial.distance.cosine(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce70b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "SNM = load_model(\"C:\\\\Users\\\\raghavendra.s.k\\\\Desktop\\\\Files\\\\LV\\\\Siamese_model_VGG.h5\")\n",
    "SNM1 = load_model(\"C:\\\\Users\\\\raghavendra.s.k\\\\Desktop\\\\Files\\\\LV\\\\Siamese_model_Mobilenet_V3_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76c556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = SNM.predict(np.expand_dims(Image_resize(\"C:\\\\Users\\\\raghavendra.s.k\\\\Desktop\\\\Files\\\\LV\\\\Anchor\\\\Raghavendra.S.K.png\"), axis = 0))\n",
    "image2 = SNM.predict(np.expand_dims(Image_resize(\"C:\\\\Users\\\\raghavendra.s.k\\\\Desktop\\\\Files\\\\LV\\\\Negative\\\\Rajat.jpg\"), axis = 0))\n",
    "# C:\\Users\\raghavendra.s.k\\Desktop\\Files\\LV\\Negative\\Rajat.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a87f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = euclidean_distance(image1,image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d99afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6613891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19830af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d8018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6613891]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879e6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = Tk()\n",
    "label=Label(root,text=\"I was Hidden\")\n",
    "\n",
    "def labelactive():\n",
    "    label.pack()\n",
    "    \n",
    "def labeldeactive():\n",
    "    label.pack_forget()\n",
    "    \n",
    "    \n",
    "Button(root,text=\"Show\",command=labelactive).pack()\n",
    "Button(root,text=\"Hide\",command=labeldeactive).pack()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59915354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
